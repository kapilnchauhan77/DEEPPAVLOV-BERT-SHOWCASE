{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deeppavlov BERT Showcase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapilnchauhan77/DEEPPAVLOV-BERT-SHOWCASE/blob/master/Deeppavlov_BERT_Showcase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM-31VUyt62T",
        "colab_type": "text"
      },
      "source": [
        "# Deeppavlov BERT Showcase\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwzl_A0MDJ2v",
        "colab_type": "code",
        "outputId": "57162613-4b95-4a4a-dff2-24918c1d6bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! pip install deeppavlov"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deeppavlov\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/9d/453d101981b293441be889ba91d6983abdeeb2b3abc070b47a4044f6a64b/deeppavlov-0.7.1-py3-none-any.whl (735kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 2.8MB/s \n",
            "\u001b[?25hCollecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (3.2.5)\n",
            "Collecting tqdm==4.32.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/3d/7a6b68b631d2ab54975f3a4863f3c4e9b26445353264ef01f465dc9b0208/tqdm-4.32.2-py2.py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Collecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 24.0MB/s \n",
            "\u001b[?25hCollecting scipy==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2MB 1.2MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n",
            "\u001b[?25hCollecting h5py==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 46.2MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/2f/b08ad77c639040baafc891621f0cfdb209e2266404ca13c3167970a6f6d6/Cython-0.29.12-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 41.4MB/s \n",
            "\u001b[?25hCollecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 59.5MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/5e/9711642455c4e17b1202d4f6403ede0fef37fc145038aee7193f3b24445e/pyTelegramBotAPI-3.6.6.tar.gz (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hCollecting overrides==1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/de/55/3100c6d14c1ed177492fcf8f07c4a7d2d6c996c0a7fc6a9a0a41308e7eec/overrides-1.9.tar.gz\n",
            "Collecting pyopenssl==19.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/c8/ceb170d81bd3941cbeb9940fc6cc2ef2ca4288d0ca8929ea4db5905d904d/pyOpenSSL-19.0.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.4MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/a9/2ab492155d9b76cf109c2370e201822ba3c7f4aed85f5a1b4d22907e7206/uvicorn-0.9.0.tar.gz\n",
            "Collecting fuzzywuzzy==0.17.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Collecting fastapi==0.38.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/59/1a42dde38f1ae2a7a318947e54fabd1fc02ac423ecc91957c417065e7cc6/fastapi-0.38.1-py3-none-any.whl (160kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 45.8MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0MB 21.5MB/s \n",
            "\u001b[?25hCollecting pandas==0.24.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 44.1MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 243kB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 42.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.2.5->deeppavlov) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov) (0.14.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (1.0.8)\n",
            "Collecting cryptography>=2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 35.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (7.0)\n",
            "Collecting h11==0.8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/f3/8e4cf5fa1a3d8bda942a0b1cf92f87815494216fd439f82eb99073141ba0/h11-0.8.1-py2.py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.9MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.2MB/s \n",
            "\u001b[?25hCollecting httptools==0.0.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/03/215969db11abe8741e9c266a4cbe803a372bd86dd35fa0084c4df6d4bd00/httptools-0.0.13.tar.gz (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 44.4MB/s \n",
            "\u001b[?25hCollecting uvloop==0.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/48/586225bbb02d3bdca475b17e4be5ce5b3f09da2d6979f359916c1592a687/uvloop-0.14.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 33.1MB/s \n",
            "\u001b[?25hCollecting starlette<=0.12.8,>=0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/4a/90a6a8685fcbdcf544a2293d0d0211ecba3cd7f309b831499d5c895383cb/starlette-0.12.8.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hCollecting pydantic<=0.32.2,>=0.32.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/78/2edcc6e65ec020403ac6ba6deb54c1cf227c49232ce9d98a1ae7ebdfa3a1/pydantic-0.32.2-cp36-cp36m-manylinux1_x86_64.whl (5.1MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1MB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->deeppavlov) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->deeppavlov) (2.6.1)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.3->pyopenssl==19.0.0->deeppavlov) (1.13.2)\n",
            "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic<=0.32.2,>=0.32.2->fastapi==0.38.1->deeppavlov) (0.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3->pyopenssl==19.0.0->deeppavlov) (2.19)\n",
            "Building wheels for collected packages: pytelegrambotapi, overrides, uvicorn, httptools, starlette\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.6-cp36-none-any.whl size=44856 sha256=3486958659c5fb810aa40cd448672e8876542bef91df4d59288043d7e5e7c066\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/69/d7/26f1fb04ac4d4c95bff643cea765a8e91c4348da25b4744e08\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-1.9-cp36-none-any.whl size=4214 sha256=66aa36470ee72549e460454bfaf69a211ea7fd285e1622382615ac19ae2c74eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/52/86/e5a83b1797e7d263b458d2334edd2704c78508b3eea9323718\n",
            "  Building wheel for uvicorn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uvicorn: filename=uvicorn-0.9.0-cp36-none-any.whl size=37118 sha256=911e5b79061f849fdbb13277ecaf610f5320fb0e8da8624826abb26dad3e5c19\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/e5/d1/a50d405d3bb18fac538ef9606ed9b6cd5efb6e06b6de834507\n",
            "  Building wheel for httptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httptools: filename=httptools-0.0.13-cp36-cp36m-linux_x86_64.whl size=212544 sha256=bf08b78b22110d74a26c220c5054d0053eb13c84718cf98e0bc79b0e4f8557d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/3e/2e/013f99b42efc25cf3589730cf380738e46b1e5edaf2f78d525\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.8-cp36-none-any.whl size=56910 sha256=ce346e527575c302ef371f387a934b8a64ba173db1de9ccea2b37353699facc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a0/1d/17eb20c5742e3236799a7883e56325823d57fcd8ce2a0c9348\n",
            "Successfully built pytelegrambotapi overrides uvicorn httptools starlette\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.25.0; python_version >= \"3.0\", but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts, pymorphy2, tqdm, rusenttokenize, numpy, scipy, scikit-learn, requests, h5py, Cython, keras, pytelegrambotapi, overrides, cryptography, pyopenssl, h11, websockets, httptools, uvloop, uvicorn, fuzzywuzzy, starlette, pydantic, fastapi, pymorphy2-dicts-ru, pandas, deeppavlov\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "  Found existing installation: numpy 1.17.4\n",
            "    Uninstalling numpy-1.17.4:\n",
            "      Successfully uninstalled numpy-1.17.4\n",
            "  Found existing installation: scipy 1.3.3\n",
            "    Uninstalling scipy-1.3.3:\n",
            "      Successfully uninstalled scipy-1.3.3\n",
            "  Found existing installation: scikit-learn 0.21.3\n",
            "    Uninstalling scikit-learn-0.21.3:\n",
            "      Successfully uninstalled scikit-learn-0.21.3\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: h5py 2.8.0\n",
            "    Uninstalling h5py-2.8.0:\n",
            "      Successfully uninstalled h5py-2.8.0\n",
            "  Found existing installation: Cython 0.29.14\n",
            "    Uninstalling Cython-0.29.14:\n",
            "      Successfully uninstalled Cython-0.29.14\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "  Found existing installation: pandas 0.25.3\n",
            "    Uninstalling pandas-0.25.3:\n",
            "      Successfully uninstalled pandas-0.25.3\n",
            "Successfully installed Cython-0.29.12 cryptography-2.8 dawg-python-0.7.2 deeppavlov-0.7.1 fastapi-0.38.1 fuzzywuzzy-0.17.0 h11-0.8.1 h5py-2.9.0 httptools-0.0.13 keras-2.2.4 numpy-1.16.4 overrides-1.9 pandas-0.24.2 pydantic-0.32.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.404381.4453942 pyopenssl-19.0.0 pytelegrambotapi-3.6.6 requests-2.22.0 rusenttokenize-0.0.5 scikit-learn-0.21.2 scipy-1.3.0 starlette-0.12.8 tqdm-4.32.2 uvicorn-0.9.0 uvloop-0.14.0 websockets-8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas",
                  "requests",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMnCgXDNt2cD",
        "colab_type": "text"
      },
      "source": [
        "## BERT for text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5cA1hCADs5g",
        "colab_type": "text"
      },
      "source": [
        "Install requirements for BERT-based classification model trained to detect insults in [Social Commentary](https://www.kaggle.com/c/detecting-insults-in-social-commentary):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkUU9OTHDrtY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "outputId": "9e698d7e-a2e2-4035-b4ab-4bc07566996f"
      },
      "source": [
        "! python -m deeppavlov install insults_kaggle_bert"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "email-validator not installed, email fields will be treated as str.\n",
            "To install, run: pip install email-validator\n",
            "2020-01-05 21:13:07.612 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'insults_kaggle_bert' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/classifiers/insults_kaggle_bert.json'\n",
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 116kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 25.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (42.0.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-o20ls_fh\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-o20ls_fh\n",
            "  Running command git checkout -b feat/multi_gpu --track origin/feat/multi_gpu\n",
            "  Switched to a new branch 'feat/multi_gpu'\n",
            "  Branch 'feat/multi_gpu' set up to track remote branch 'feat/multi_gpu' from 'origin'.\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-cp36-none-any.whl size=23580 sha256=c7ceff54b91063fb3fb5a01090c716b8debf759166a826fd4912d92d541a8a80\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0px7yao6/wheels/1e/41/94/886107eaf932532594886fd8bfc9cb9d4db632e94add49d326\n",
            "Successfully built bert-dp\n",
            "Installing collected packages: bert-dp\n",
            "Successfully installed bert-dp-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0AHB7nAxIHx",
        "colab_type": "text"
      },
      "source": [
        "Interact with text classification model with DeepPavlov Python API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2EMZUMJtYEj",
        "colab_type": "code",
        "outputId": "b0de55a8-f5ee-4ea8-d654-352f7ecbeb24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "from deeppavlov import build_model, configs\n",
        "\n",
        "model = build_model(configs.classifiers.insults_kaggle_bert, download=True) # download=True if model is not downloaded yet"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 17:51:53.448 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip download because of matching hashes\n",
            "2020-01-05 17:51:53.810 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/datasets/insults_data.tar.gz download because of matching hashes\n",
            "2020-01-05 17:52:02.904 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/classifiers/insults_kaggle_v3.tar.gz download because of matching hashes\n",
            "2020-01-05 17:52:02.988 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/classes.dict]\n",
            "2020-01-05 17:52:22.193 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvAr9jdUzRj_",
        "colab_type": "code",
        "outputId": "513ff8df-9bfd-48d4-9eb7-0db81d01a0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "model(['hey, how are you?', 'You are so stupid!'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Not Insult', 'Insult']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9EfsHwNrmyl",
        "colab_type": "text"
      },
      "source": [
        "**Showing How to train on your own Data set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrVwZWadz52L",
        "colab_type": "code",
        "outputId": "05ad3bc7-d1b6-4160-b6b4-a13c8c858f48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "import json\n",
        "from pprint import pprint\n",
        "model_config = json.load(open(configs.classifiers.insults_kaggle_bert))\n",
        "\n",
        "pprint(model_config['dataset_reader'])\n",
        "pprint(model_config['metadata']['variables'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'class_name': 'basic_classification_reader',\n",
            " 'data_path': '{DOWNLOADS_PATH}/insults_data',\n",
            " 'x': 'Comment',\n",
            " 'y': 'Class'}\n",
            "{'DOWNLOADS_PATH': '{ROOT_PATH}/downloads',\n",
            " 'MODELS_PATH': '{ROOT_PATH}/models',\n",
            " 'MODEL_PATH': '{MODELS_PATH}/classifiers/insults_kaggle_v3',\n",
            " 'ROOT_PATH': '~/.deeppavlov'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDfgSqqUtdGP",
        "colab_type": "text"
      },
      "source": [
        "Keep your data in this directory like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF8-DrRR2Q-T",
        "colab_type": "code",
        "outputId": "7f2b4dca-8329-4f53-9343-d131026a4200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "! ls ~/.deeppavlov/downloads/insults_data/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test.csv  train.csv  valid.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60OCJIOZ2MYd",
        "colab_type": "code",
        "outputId": "2186c28e-e8eb-4e8e-813e-9dd9e12415df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "! head ~/.deeppavlov/downloads/insults_data/train.csv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comment,Class\n",
            "\"\"\"You fuck your dad.\"\"\",Insult\n",
            "\"\"\"i really don't understand your point.\\xa0 It seems that you are mixing apples and oranges.\"\"\",Not Insult\n",
            "\"\"\"A\\\\xc2\\\\xa0majority of Canadians can and has been wrong before now and will be again.\\\\n\\\\nUnless you're supportive of the idea that nothing is full proof or perfect so you take your chances and if we should inadvertently kill your son or daughter then them's the breaks and we can always regard you as collateral damage like in wartime - and sorry, but\\\\xc2\\\\xa0the cheques in the mail. \"\"\",Not Insult\n",
            "\"\"\"listen if you dont wanna get married to a man or a women DONT DO IT. what would it bother you if gay people got married stay in your lane do you let them do them. And your god is so nice but quick to judg if your not like him, thought you wasnt suppose to judge people.\"\"\",Not Insult\n",
            "\"\"\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1eddng bi\\u1ec3u t\\xecnh 2011 c\\xf3 \\xf4n ho\\xe0 kh\\xf4ng ? \\nC\\xe1c ng\\u01b0 d\\xe2n ng\\u1ed3i cu\\xed \\u0111\\u1ea7u chi\\u1ee5 nh\\u1ee5c c\\xf3 \\xf4n ho\\xe0 kh\\xf4ng ?\\nC\\xe1c n\\xf4ng d\\xe2n gi\\u1eef \\u0111\\u1ea5t \\u1edf V\\u0103n Giang, C\\u1ea7n Th\\u01a1 c\\xf3 \\xf4n ho\\xe0 kh\\xf4ng ?\\n.................\\nR\\u1ed1t cu\\u1ed9c \\u0111\\u01b0\\u1ee3c g\\xec\\xa0 th\\xec ch\\xfang ta \\u0111\\xe3 bi\\u1ebft !\\nAi c\\u0169ng y\\xeau chu\\u1ed9ng ho\\xe0 b\\xecnh, nh\\u01b0ng \\u0111\\xf4i khi ho\\xe0 b\\xecnh ch\\u1ec9 th\\u1eadt s\\u1ef1 \\u0111\\u1ebfn sau chi\\u1ebfn tranh m\\xe0 th\\xf4i.\\nKh\\xf4ng c\\xf2n con \\u0111\\u01b0\\u1eddng n\\xe0o ch\\u1ecdn kh\\xe1c \\u0111\\xe2u, \\u0111\\u1eebng m\\u01a1 th\\xeam n\\u01b0\\xe3.\"\"\",Not Insult\n",
            "\"\"\"@SDL OK, but I would hope they'd sign him to a one-year contract to start with. Give him the chance to be reliable and productive, but give themselves the out if all his time off has hurt his playing skills or if he falls back into old habits.\"\"\",Not Insult\n",
            "\"\"\"Yeah and where are you now?\"\"\",Not Insult\n",
            "\"\"\"shut the fuck up. you and the rest of your faggot friends should be burned at the stake\"\"\",Insult\n",
            "\"\"\"Either you are fake or extremely stupid...maybe both...\"\"\",Insult\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS0xeX9Atuac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "7c41f465-b0d4-4543-f013-b08530634bdc"
      },
      "source": [
        "from deeppavlov import train_model\n",
        "model = train_model(model_config)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/trainers/nn_trainer.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 14:20:59.435 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/classes.dict]\n",
            "2020-01-05 14:20:59.442 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/classifiers/insults_kaggle_v3/classes.dict]\n",
            "2020-01-05 14:21:20.125 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 14:27:19.0 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best roc_auc of 0.9255\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 2647, \"metrics\": {\"roc_auc\": 0.9255, \"accuracy\": 0.8659, \"f1_macro\": 0.8075}, \"time_spent\": \"0:05:58\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 5}}\n",
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"roc_auc\": 0.9989, \"accuracy\": 0.9688, \"f1_macro\": 0.9626}, \"time_spent\": \"0:30:52\", \"epochs_done\": 1, \"batches_seen\": 62, \"train_examples_seen\": 3947, \"learning_rate\": 1e-05, \"loss\": 0.17253795109929576}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 14:58:08.576 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the roc_auc of 0.9255\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 2647, \"metrics\": {\"roc_auc\": 0.9158, \"accuracy\": 0.8632, \"f1_macro\": 0.825}, \"time_spent\": \"0:36:48\", \"epochs_done\": 1, \"batches_seen\": 62, \"train_examples_seen\": 3947, \"impatience\": 1, \"patience_limit\": 5}}\n",
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"roc_auc\": 1.0, \"accuracy\": 1.0, \"f1_macro\": 1.0}, \"time_spent\": \"1:01:30\", \"epochs_done\": 2, \"batches_seen\": 124, \"train_examples_seen\": 7894, \"learning_rate\": 1e-05, \"loss\": 0.061773255557542844}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 15:28:47.120 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the roc_auc of 0.9255\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 2647, \"metrics\": {\"roc_auc\": 0.9098, \"accuracy\": 0.8655, \"f1_macro\": 0.8172}, \"time_spent\": \"1:07:26\", \"epochs_done\": 2, \"batches_seen\": 124, \"train_examples_seen\": 7894, \"impatience\": 2, \"patience_limit\": 5}}\n",
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"roc_auc\": 1.0, \"accuracy\": 1.0, \"f1_macro\": 1.0}, \"time_spent\": \"1:32:04\", \"epochs_done\": 3, \"batches_seen\": 186, \"train_examples_seen\": 11841, \"learning_rate\": 1e-05, \"loss\": 0.033550254579993985}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 15:59:48.526 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the roc_auc of 0.9255\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 2647, \"metrics\": {\"roc_auc\": 0.9102, \"accuracy\": 0.8674, \"f1_macro\": 0.83}, \"time_spent\": \"1:38:28\", \"epochs_done\": 3, \"batches_seen\": 186, \"train_examples_seen\": 11841, \"impatience\": 3, \"patience_limit\": 5}}\n",
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"roc_auc\": 0.9985, \"accuracy\": 0.9844, \"f1_macro\": 0.9765}, \"time_spent\": \"2:03:09\", \"epochs_done\": 4, \"batches_seen\": 248, \"train_examples_seen\": 15788, \"learning_rate\": 1e-05, \"loss\": 0.01995556393352848}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 16:30:54.306 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the roc_auc of 0.9255\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 2647, \"metrics\": {\"roc_auc\": 0.9063, \"accuracy\": 0.8663, \"f1_macro\": 0.8272}, \"time_spent\": \"2:09:33\", \"epochs_done\": 4, \"batches_seen\": 248, \"train_examples_seen\": 15788, \"impatience\": 4, \"patience_limit\": 5}}\n",
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"roc_auc\": 1.0, \"accuracy\": 1.0, \"f1_macro\": 1.0}, \"time_spent\": \"2:34:46\", \"epochs_done\": 5, \"batches_seen\": 310, \"train_examples_seen\": 19735, \"learning_rate\": 1e-05, \"loss\": 0.018101048049321698}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 17:02:33.515 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the roc_auc of 0.9255\n",
            "2020-01-05 17:02:34.222 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 2.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 2647, \"metrics\": {\"roc_auc\": 0.9114, \"accuracy\": 0.8708, \"f1_macro\": 0.8265}, \"time_spent\": \"2:41:13\", \"epochs_done\": 5, \"batches_seen\": 310, \"train_examples_seen\": 19735, \"impatience\": 5, \"patience_limit\": 5}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 17:02:34.920 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 328: Ran out of patience\n",
            "2020-01-05 17:02:35.316 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/classes.dict]\n",
            "2020-01-05 17:02:56.859 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/model\n",
            "{\"train\": {\"eval_examples_count\": 3947, \"metrics\": {\"roc_auc\": 0.9905, \"accuracy\": 0.9572, \"f1_macro\": 0.9431}, \"time_spent\": \"0:09:43\"}}\n",
            "{\"valid\": {\"eval_examples_count\": 2647, \"metrics\": {\"roc_auc\": 0.9255, \"accuracy\": 0.8659, \"f1_macro\": 0.8075}, \"time_spent\": \"0:06:35\"}}\n",
            "{\"test\": {\"eval_examples_count\": 2235, \"metrics\": {\"roc_auc\": 0.8612, \"accuracy\": 0.74, \"f1_macro\": 0.7235}, \"time_spent\": \"0:05:29\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 17:24:44.154 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/classes.dict]\n",
            "2020-01-05 17:25:05.488 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/classifiers/insults_kaggle_v3/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "513ff8df-9bfd-48d4-9eb7-0db81d01a0e5",
        "id": "eoAuZjR_ewld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "model(['Your work was great', 'Your content is Horrible!!!'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Not Insult', 'Insult']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgF8YVeHuAi0",
        "colab_type": "text"
      },
      "source": [
        "## BERT for tagging (Named Entity Recognition)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIOLrEv8un2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "830dcc98-1e06-479e-a753-d568fb5c6c96"
      },
      "source": [
        "! python -m deeppavlov interact ner_ontonotes_bert -d"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "email-validator not installed, email fields will be treated as str.\n",
            "To install, run: pip install email-validator\n",
            "2020-01-05 17:25:09.346 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'ner_ontonotes_bert' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ner/ner_ontonotes_bert.json'\n",
            "2020-01-05 17:25:10.120 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_bert_v1.tar.gz?config=ner_ontonotes_bert to /root/.deeppavlov/ner_ontonotes_bert_v1.tar.gz\n",
            "100% 805M/805M [02:11<00:00, 6.10MB/s]\n",
            "2020-01-05 17:27:21.934 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/ner_ontonotes_bert_v1.tar.gz archive into /root/.deeppavlov/models\n",
            "2020-01-05 17:27:32.127 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip?config=ner_ontonotes_bert download because of matching hashes\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Package perluniprops is already up-to-date!\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "2020-01-05 17:27:34.777 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes_bert/tag.dict]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2020-01-05 17:27:34.842051: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-01-05 17:27:34.845923: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-01-05 17:27:34.846315: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b26a00 executing computations on platform Host. Devices:\n",
            "2020-01-05 17:27:34.846355: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "2020-01-05 17:27:56.503151: W tensorflow/core/framework/allocator.cc:107] Allocation of 89075712 exceeds 10% of system memory.\n",
            "2020-01-05 17:27:56.553207: W tensorflow/core/framework/allocator.cc:107] Allocation of 89075712 exceeds 10% of system memory.\n",
            "2020-01-05 17:27:57.906829: W tensorflow/core/framework/allocator.cc:107] Allocation of 89075712 exceeds 10% of system memory.\n",
            "2020-01-05 17:27:57.926094: W tensorflow/core/framework/allocator.cc:107] Allocation of 89075712 exceeds 10% of system memory.\n",
            "2020-01-05 17:27:58.395957: W tensorflow/core/framework/allocator.cc:107] Allocation of 89075712 exceeds 10% of system memory.\n",
            "2020-01-05 17:28:00.360776: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-01-05 17:28:04.661 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_ontonotes_bert/model]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "x::Peter went to play football at the club\n",
            ">> (['Peter', 'went', 'to', 'play', 'football', 'at', 'the', 'club'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])\n",
            "x::Germany Won the match\n",
            ">> (['Germany', 'Won', 'the', 'match'], ['B-GPE', 'O', 'O', 'O'])\n",
            "x::Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/deeppavlov/__main__.py\", line 4, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/deeppavlov/deep.py\", line 79, in main\n",
            "    interact_model(pipeline_config_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/deeppavlov/core/commands/infer.py\", line 83, in interact_model\n",
            "    args.append((input('{}::'.format(in_x)),))\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B3Is4zK17hT3",
        "outputId": "0c131847-8d21-40d8-8400-411645571ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from deeppavlov import build_model, configs\n",
        "\n",
        "model = build_model(configs.ner.ner_ontonotes_bert_mult, download=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 20:57:52.217 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip to /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip\n",
            "2020-01-05 20:57:52.218 WARNING in 'deeppavlov.core.data.utils'['utils'] at line 89: Found a partial download /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip.part\n",
            " 11%|█▏        | 74.6M/663M [00:00<?, ?B/s]2020-01-05 20:57:52.222 WARNING in 'deeppavlov.core.data.utils'['utils'] at line 93: Download stopped abruptly, trying to resume from 74579968 to reach 662903077\n",
            "100%|██████████| 663M/663M [03:03<00:00, 3.62MB/s]\n",
            "2020-01-05 21:00:55.477 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip archive into /root/.deeppavlov/downloads/bert_models\n",
            "2020-01-05 21:01:02.384 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_bert_mult_v1.tar.gz to /root/.deeppavlov/ner_ontonotes_bert_mult_v1.tar.gz\n",
            "100%|██████████| 1.32G/1.32G [06:53<00:00, 3.19MB/s]\n",
            "2020-01-05 21:07:55.756 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/ner_ontonotes_bert_mult_v1.tar.gz archive into /root/.deeppavlov/models\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 21:08:12.287 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes_bert_mult/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 21:08:45.466 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_ontonotes_bert_mult/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes_bert_mult/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulkp8sO-KBdw",
        "colab_type": "code",
        "outputId": "3bac3543-2d1f-4aec-dade-07a767ed2675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "model(['Curling World Championship will be held in Antananarivo'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['Curling',\n",
              "   'World',\n",
              "   'Championship',\n",
              "   'will',\n",
              "   'be',\n",
              "   'held',\n",
              "   'in',\n",
              "   'Antananarivo']],\n",
              " [['B-EVENT', 'I-EVENT', 'I-EVENT', 'O', 'O', 'O', 'O', 'B-GPE']]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MgYfZQWuzh0",
        "colab_type": "text"
      },
      "source": [
        "## BERT for Question Answering (Stanford Question Answering Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKkNvAHLu2Wx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "07c3f840-1c42-47ce-e992-5894cea77997"
      },
      "source": [
        "from deeppavlov import build_model, configs\n",
        "\n",
        "model = build_model(configs.squad.squad_bert, download=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 21:14:22.951 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip download because of matching hashes\n",
            "2020-01-05 21:14:31.665 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_bert.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 21:14:52.81 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/squad_bert/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/squad_bert/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGOBhJCOu3qV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1d48e7cc-e61a-4093-828c-1c2cc2ef3ff1"
      },
      "source": [
        "model(['In meteorology, precipitation is any product of the condensation of atmospheric water vapor that falls under gravity. The main forms of precipitation include drizzle, rain, sleet, snow, graupel and hail… Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals within a cloud. Short, intense periods of rain in scattered locations are called “showers”.'], \n",
        "      ['Where do water droplets collide with ice crystals to form precipitation?'])[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['within a cloud']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o23VDxPavB2U",
        "colab_type": "text"
      },
      "source": [
        "## Check if the paraphrases of both texts are same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz27nkJdvDfo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "a9cd7e2f-0ef9-4017-c5a2-cb46a3f6f9a2"
      },
      "source": [
        "! python -m deeppavlov install paraphraser_bert"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "email-validator not installed, email fields will be treated as str.\n",
            "To install, run: pip install email-validator\n",
            "2020-01-05 17:42:02.700 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'paraphraser_bert' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/classifiers/paraphraser_bert.json'\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (42.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-lnv0je0j\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-lnv0je0j\n",
            "  Running command git checkout -b feat/multi_gpu --track origin/feat/multi_gpu\n",
            "  Switched to a new branch 'feat/multi_gpu'\n",
            "  Branch 'feat/multi_gpu' set up to track remote branch 'feat/multi_gpu' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): bert-dp==1.0 from git+https://github.com/deepmipt/bert.git@feat/multi_gpu in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-cp36-none-any.whl size=23580 sha256=87fec324f1c4897756902d00773de0a69d261654e32babefd7a20787100bc4bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y3nl9xnr/wheels/1e/41/94/886107eaf932532594886fd8bfc9cb9d4db632e94add49d326\n",
            "Successfully built bert-dp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0bIe8AtvFLT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "73fbe7e6-a3cf-4f3e-f302-90d9420c0a1a"
      },
      "source": [
        "from deeppavlov import build_model, configs\n",
        "\n",
        "model = build_model(configs.classifiers.paraphraser_bert, download=True) # download=True if model is not downloaded yet"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 17:59:44.548 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/datasets/paraphraser.zip download because of matching hashes\n",
            "INFO:deeppavlov.download:Skipped http://files.deeppavlov.ai/datasets/paraphraser.zip download because of matching hashes\n",
            "2020-01-05 17:59:46.317 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip download because of matching hashes\n",
            "INFO:deeppavlov.download:Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip download because of matching hashes\n",
            "2020-01-05 17:59:49.572 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/classifiers/paraphraser_bert_v0.tar.gz download because of matching hashes\n",
            "INFO:deeppavlov.download:Skipped http://files.deeppavlov.ai/deeppavlov_data/classifiers/paraphraser_bert_v0.tar.gz download because of matching hashes\n",
            "2020-01-05 17:59:49.852 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/datasets/paraphraser_gold.zip download because of matching hashes\n",
            "INFO:deeppavlov.download:Skipped http://files.deeppavlov.ai/datasets/paraphraser_gold.zip download because of matching hashes\n",
            "2020-01-05 18:00:13.561 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/paraphraser_bert_v0/model_multi]\n",
            "INFO:deeppavlov.core.models.tf_model:[loading model from /root/.deeppavlov/models/paraphraser_bert_v0/model_multi]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/paraphraser_bert_v0/model_multi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/paraphraser_bert_v0/model_multi\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TntoSzOvvG8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f57d11c6-1605-438f-8910-4a06ff77da34"
      },
      "source": [
        "model([\"I am great\"], [\"I am good\"])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaiRBMtc1PpL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5bee6592-11c3-4988-c469-b3c8308c7654"
      },
      "source": [
        "model([\"This is worse than I expected\"], [\"I thing this is great\"])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlkLnisEvKpd",
        "colab_type": "text"
      },
      "source": [
        "## Summarizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36TCWdxhvLd9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "6de52e39-88b2-41d5-9a63-39351e877560"
      },
      "source": [
        "! python -m deeppavlov install bert_as_summarizer"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "email-validator not installed, email fields will be treated as str.\n",
            "To install, run: pip install email-validator\n",
            "2020-01-05 17:56:00.910 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'bert_as_summarizer' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/summarization/bert_as_summarizer.json'\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.8)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (42.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-2f7kestp\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-2f7kestp\n",
            "  Running command git checkout -b feat/multi_gpu --track origin/feat/multi_gpu\n",
            "  Switched to a new branch 'feat/multi_gpu'\n",
            "  Branch 'feat/multi_gpu' set up to track remote branch 'feat/multi_gpu' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): bert-dp==1.0 from git+https://github.com/deepmipt/bert.git@feat/multi_gpu in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-cp36-none-any.whl size=23580 sha256=d0c1eaed56001f3ba57f7ab41a5ac1cd7af9ab81ecc356b347bc1f363604d55d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fd62_crj/wheels/1e/41/94/886107eaf932532594886fd8bfc9cb9d4db632e94add49d326\n",
            "Successfully built bert-dp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXsbr9iIvM8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1f011bf9-d5c9-4397-937f-e37cc3eb4b6e"
      },
      "source": [
        "from deeppavlov import build_model, configs\n",
        "\n",
        "model = build_model(configs.summarization.bert_as_summarizer , download=True) # download=True if model is not downloaded yet"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 17:56:09.577 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v2.tar.gz download because of matching hashes\n",
            "2020-01-05 17:56:16.125 INFO in 'deeppavlov.models.bert.bert_as_summarizer'['bert_as_summarizer'] at line 102: [initializing model with Bert from /root/.deeppavlov/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v2/bert_model.ckpt]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxi1FMGR2-2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f58b3bd1-9514-4539-b361-2f43bd50bdf8"
      },
      "source": [
        "model([\"The U.S. is ready to engage in talks about North Korea’s nuclear program even as it maintains pressure on Kim Jong Un’s regime, \\\n",
        "the Washington Post reported, citing an interview with Vice President Mike Pence. Pence and South Korea’s President Moon Jae-in agreed on \\\n",
        "a post-Olympics strategy during conversations at the Winter Olympics in the South Korean resort of Pyeongchang that Pence dubbed “maximum pressure \\\n",
        "and engagement at the same time.” Pence spoke in an interview on his way home from the Winter Olympics. “The point is, no pressure comes off until they \\\n",
        "are actually doing something that the alliance believes represents a meaningful step toward denuclearization,” the Post quoted Pence as saying. \\\n",
        "“So the maximum pressure campaign is going to continue and intensify. But if you want to talk, we’ll talk.”\"])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The U.S. is ready to engage in talks about North Korea’s nuclear program even as it maintains pressure on Kim Jong Un’s regime, the Washington Post reported, citing an interview with Vice President Mike Pence.',\n",
              "  '“The point is, no pressure comes off until they are actually doing something that the alliance believes represents a meaningful step toward denuclearization,” the Post quoted Pence as saying.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYkQBDEqwtvW",
        "colab_type": "text"
      },
      "source": [
        "## Open Domain QA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX8b2DKJwwj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        },
        "outputId": "b50d80e1-ab7b-4834-c54c-683a1dae842b"
      },
      "source": [
        "!python -m deeppavlov install en_odqa_infer_wiki"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "email-validator not installed, email fields will be treated as str.\n",
            "To install, run: pip install email-validator\n",
            "2020-01-05 18:48:34.790 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'en_odqa_infer_wiki' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/odqa/en_odqa_infer_wiki.json'\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (42.0.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
            "Requirement already satisfied: spacy==2.1.3 in /usr/local/lib/python3.6/dist-packages (2.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (1.16.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (2.22.0)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (2.0.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (0.9.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (0.2.0)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (2.6.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (0.4.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (0.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (2.0.3)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (7.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.1.3) (1.0.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3) (1.24.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy==2.1.3) (4.32.2)\n",
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.1.0) (2.1.3)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->en_core_web_sm==2.1.0) (0.2.4)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->en_core_web_sm==2.1.0) (2.0.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->en_core_web_sm==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->en_core_web_sm==2.1.0) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->en_core_web_sm==2.1.0) (0.4.2)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->en_core_web_sm==2.1.0) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->en_core_web_sm==2.1.0) (0.9.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->en_core_web_sm==2.1.0) (1.16.4)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->en_core_web_sm==2.1.0) (2.6.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->en_core_web_sm==2.1.0) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->en_core_web_sm==2.1.0) (2.22.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->en_core_web_sm==2.1.0) (4.32.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->en_core_web_sm==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->en_core_web_sm==2.1.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->en_core_web_sm==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->en_core_web_sm==2.1.0) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47dQfZQdw1O2",
        "colab_type": "text"
      },
      "source": [
        "Training for own data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpupQZmHwx9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deeppavlov import configs\n",
        "from deeppavlov.core.commands.train import train_evaluate_model_from_config\n",
        "\n",
        "train_evaluate_model_from_config(configs.doc_retrieval.en_ranker_tfidf_wiki, download=True)\n",
        "train_evaluate_model_from_config(configs.squad.multi_squad_noans, download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXNaWQt8KgY2",
        "colab_type": "text"
      },
      "source": [
        "Build Model with the training done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN-LozjQw4xF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deeppavlov import configs\n",
        "from deeppavlov.core.commands.infer import build_model\n",
        "\n",
        "odqa = build_model(configs.odqa.en_odqa_infer_wiki, load_trained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B972rXNnCg-B",
        "colab_type": "text"
      },
      "source": [
        "Build Model from the available pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFx3C6lMKX9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9cc0176e-a8f1-4e7d-fdf5-eebfb3e9b866"
      },
      "source": [
        "from deeppavlov import configs\n",
        "from deeppavlov.core.commands.infer import build_model\n",
        "odqa = build_model(configs.odqa.en_odqa_infer_wiki, download = True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 19:23:30.608 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/multi_squad_model_noans_1.1.tar.gz to /root/.deeppavlov/multi_squad_model_noans_1.1.tar.gz\n",
            "100%|██████████| 265M/265M [01:48<00:00, 2.44MB/s]\n",
            "2020-01-05 19:25:19.82 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/multi_squad_model_noans_1.1.tar.gz archive into /root/.deeppavlov/models\n",
            "2020-01-05 19:25:26.175 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/datasets/wikipedia/enwiki.tar.gz to /root/.deeppavlov/enwiki.tar.gz\n",
            "2020-01-05 19:25:26.177 WARNING in 'deeppavlov.core.data.utils'['utils'] at line 89: Found a partial download /root/.deeppavlov/enwiki.tar.gz.part\n",
            "  0%|          | 12.1M/4.81G [00:00<?, ?B/s]2020-01-05 19:25:26.180 WARNING in 'deeppavlov.core.data.utils'['utils'] at line 93: Download stopped abruptly, trying to resume from 12124160 to reach 4812269240\n",
            "100%|██████████| 4.81G/4.81G [20:40<00:00, 3.88MB/s]\n",
            "2020-01-05 19:46:06.726 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/enwiki.tar.gz archive into /root/.deeppavlov/downloads\n",
            "2020-01-05 19:49:45.870 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/en_odqa.tar.gz to /root/.deeppavlov/en_odqa.tar.gz\n",
            "100%|██████████| 4.69G/4.69G [24:45<00:00, 3.16MB/s]\n",
            "2020-01-05 20:14:31.459 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/en_odqa.tar.gz archive into /root/.deeppavlov/models\n",
            "2020-01-05 20:19:09.38 INFO in 'deeppavlov.models.vectorizers.hashing_tfidf_vectorizer'['hashing_tfidf_vectorizer'] at line 264: Loading tfidf matrix from /root/.deeppavlov/models/odqa/enwiki_tfidf_matrix.npz\n",
            "2020-01-05 20:24:41.239 INFO in 'deeppavlov.dataset_iterators.sqlite_iterator'['sqlite_iterator'] at line 57: Connecting to database, path: /root/.deeppavlov/downloads/odqa/enwiki.db\n",
            "2020-01-05 20:25:24.659 INFO in 'deeppavlov.dataset_iterators.sqlite_iterator'['sqlite_iterator'] at line 112: SQLite iterator: The size of the database is 5180368 documents\n",
            "2020-01-05 20:25:24.682 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /root/.deeppavlov/models/multi_squad_model_noans/emb/vocab_embedder.pckl\n",
            "2020-01-05 20:25:29.936 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /root/.deeppavlov/models/multi_squad_model_noans/emb/char_vocab_embedder.pckl\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/common/check_gpu.py:29: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:224: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:102: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:139: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 20:25:36.164 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:122: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:591: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:596: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:133: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:139: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:155: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:808: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "seq_dim is deprecated, use seq_axis instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "batch_dim is deprecated, use batch_axis instead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 20:25:37.749 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
            "2020-01-05 20:25:37.890 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
            "2020-01-05 20:25:37.986 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/utils.py:87: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/utils.py:101: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/utils.py:171: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:193: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/utils.py:139: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:203: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:212: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/squad/squad.py:93: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:50: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 20:25:51.395 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/multi_squad_model_noans/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/multi_squad_model_noans/model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/deeppavlov/models/doc_retrieval/logit_ranker.py:65: FutureWarning: LogitRanker.__call__() API will be changed in the future release. Instead of returning Tuple(List[str], List[float] will return Tuple(List[List[str]], List[List[float]]).\n",
            "  ' Tuple(List[List[str]], List[List[float]]).', FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Argentina', '15-16 August 1952', '14 July 1789']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wSArorScZU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fa223790-6316-4eeb-ca49-d49ddd477625"
      },
      "source": [
        "predicted_answers = odqa([\"Where did guinea pigs originate?\", \"When did the Lynmouth floods happen?\", 'What is the name of Darth Vader\\'s son?'])\n",
        "real_answers = [\"Argentina\", \"15-16 August 1952\", \"Anakin Skywalker\"]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/deeppavlov/models/doc_retrieval/logit_ranker.py:65: FutureWarning: LogitRanker.__call__() API will be changed in the future release. Instead of returning Tuple(List[str], List[float] will return Tuple(List[List[str]], List[List[float]]).\n",
            "  ' Tuple(List[List[str]], List[List[float]]).', FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCq6w6SVcvaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "3636c8eb-bcd1-43bd-c3ea-4c86b1c9936e"
      },
      "source": [
        "for i, j in zip(predicted_answers, real_answers):\n",
        "  print(f\"Predicted - {i} \\nReal- {j}\\n\\n\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted - Andes of South America \n",
            "Real- Argentina\n",
            "\n",
            "\n",
            "Predicted - 1804 \n",
            "Real- 15-16 August 1952\n",
            "\n",
            "\n",
            "Predicted - Fox Mulder \n",
            "Real- Anakin Skywalker\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swiXQxFLvTAS",
        "colab_type": "text"
      },
      "source": [
        "## Search Ranking from Databse about a given question\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c0mD2XhvUNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "dbcb498f-e47e-4182-ff7d-f086abce7dfc"
      },
      "source": [
        "!python -m deeppavlov install ranking_insurance"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "email-validator not installed, email fields will be treated as str.\n",
            "To install, run: pip install email-validator\n",
            "2020-01-05 12:49:37.414 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'ranking_insurance' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ranking/ranking_insurance.json'\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (42.0.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
            "Collecting pybind11==2.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/90/0f92a575dc60c8fba6d0c91d6b45abdb1058da9ebed40400cbcfad2ac0a7/pybind11-2.2.3-py2.py3-none-any.whl (144kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 2.6MB/s \n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.2.3\n",
            "Collecting fastText==0.8.22\n",
            "  Cloning https://github.com/deepmipt/fastText.git to /tmp/pip-install-yw6j_u_0/fastText\n",
            "  Running command git clone -q https://github.com/deepmipt/fastText.git /tmp/pip-install-yw6j_u_0/fastText\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fastText==0.8.22) (2.2.3)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fastText==0.8.22) (42.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastText==0.8.22) (1.16.4)\n",
            "Building wheels for collected packages: fastText\n",
            "  Building wheel for fastText (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastText: filename=fasttext-0.8.22-cp36-cp36m-linux_x86_64.whl size=2136202 sha256=269d8103a494f3673203ac1b9c8647c29191d88e6aeb0f05b4a03edd8caf3526\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ftz7hpw2/wheels/19/a8/8d/f2d5f95a573a8bbf7e818c1914e80d72899233bfb111c04539\n",
            "Successfully built fastText\n",
            "Installing collected packages: fastText\n",
            "Successfully installed fastText-0.8.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysdyxpLIvVfW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "1c919ffe-a7b4-4de4-e648-279cba0cbc82"
      },
      "source": [
        "from deeppavlov import build_model, configs\n",
        "\n",
        "rank_model = build_model(configs.ranking.ranking_insurance_interact, download=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-05 12:50:27.386 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/datasets/insuranceQA-master.zip to /root/.deeppavlov/downloads/insuranceQA-master.zip\n",
            "100%|██████████| 277M/277M [01:39<00:00, 2.79MB/s]\n",
            "2020-01-05 12:52:06.609 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/downloads/insuranceQA-master.zip archive into /root/.deeppavlov/downloads/insurance_data\n",
            "2020-01-05 12:52:09.217 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/insurance_ranking.tar.gz to /root/.deeppavlov/insurance_ranking.tar.gz\n",
            "100%|██████████| 8.49M/8.49M [00:04<00:00, 1.79MB/s]\n",
            "2020-01-05 12:52:13.963 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/insurance_ranking.tar.gz archive into /root/.deeppavlov/models\n",
            "2020-01-05 12:52:15.297 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/embeddings/wiki.en.bin to /root/.deeppavlov/downloads/embeddings/wiki.en.bin\n",
            "100%|██████████| 8.49G/8.49G [30:40<00:00, 4.61MB/s]\n",
            "2020-01-05 13:22:55.843 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/insurance_vocabs/sent.dict]\n",
            "2020-01-05 13:22:55.997 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/insurance_vocabs/tok.dict]\n",
            "2020-01-05 13:22:56.90 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 67: [loading fastText embeddings from `/root/.deeppavlov/downloads/embeddings/wiki.en.bin`]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flbYRx28YQvQ",
        "colab_type": "code",
        "outputId": "0efe1263-ecec-49a1-85c5-686f7a29fa1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "rank_model(['how much to pay for auto insurance?'])   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['there be several carrier who will offer an 18 year old in Minnesota car insurance coverage what be probably important to you be who will give you the good coverage at the low price get this you shall seek out the help of an agent who be license sell auto insurance in your state who can show you various auto insurance quote',\n",
              "  'cheap car insurance for young driver be available if you know where look many reputable insurer offer low down payment and cheap rate shopping for these good offer be best handle an experienced auto insurance broker with preferably 20 year or more experience not only do we help our client find the good deal but our website offer free information and advice that can often help reduce premium there be no fee or charge and take care of client be the top priority broker do not charge fee and we do the shopping so our customer save that be not a bad deal try us and let us find cheap auto insurance price for teenager',\n",
              "  'you can get free auto insurance quote a number of different way perhaps the easy method and the ones that provide the good price be contact an experienced broker and/or their website as an experienced broker 33 year we do the shopping for our customer so they be able compare the low rate from top rate company our website make it easy consumer provide a zip code , view the good option and get quote securely safely online of course you never pay fee when request or view free quote and there be never any obligation if you ever visit a website and be ask pay a fee or provide a credit card number leave immediately car insurance price be base on many factor include age , the type of vehicle you drive , your zip code and available discount as an experienced broker we help you find the most affordable option so you can maximize your coverage and pay the least']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}